\chapter{From Classical to Intuitionistic Probability}

\pubdata{\textit{Notre Dame Journal of Formal Logic}  44 (2003): 111-123.  Thanks to Alan HÃ¡jek, Graham Oppy and, especially, Lloyd Humberstone for comments and suggestions on various drafts of this paper.}

\begin{quote}
\noindent {\textit
Abstract
\par}
\noindent We generalize the Kolmogorov axioms for probability calculus to obtain conditions defining, for any given logic, a class of probability functions relative to that logic, coinciding with the standard probability functions in the special case of classical logic but allowing consideration of other classes of ``essentially Kolmogorovian'' probability functions relative to other logics. We take a broad view of the Bayesian approach as dictating \textit{inter alia} that from the perspective of a given logic, rational degrees of belief are those representable by probability functions from the class appropriate to that logic. Classical Bayesianism, which fixes the logic as classical logic, is only one version of this general approach. Another, which we call Intuitionistic Bayesianism, selects intuitionistic logic as the preferred logic and the associated class of probability functions as the right class of candidate representions of epistemic states (rational allocations of degrees of belief). Various objections to classical Bayesianism are, we argue, best met by passing to intuitionistic Bayesianism -- in which the probability functions are taken relative to intuitionistic logic -- rather than by adopting a radically non-Kolmogorovian, e.g. non-additive, conception of (or substitute for) probability functions, in spite of the popularity of the latter response amongst those who have raised these objections. The interest of intuitionistic Bayesianism is further enhanced by the availability of a Dutch Book argument justifying the selection of intuitionistic probability functions as guides to rational betting behaviour when due consideration is paid to the fact that bets are settled only when/if the outcome betted on becomes known.
\end{quote}

\section{Introduction}

It is a standard claim of modern Bayesian epistemology that reasonable epistemic states should be representable by probability functions. There have been a number of authors who have opposed this claim. For example, it has been claimed that epistemic states should be representable by Zadeh's fuzzy sets, Dempster and Shafer's evidence functions, Shackle's potential surprise functions, Cohen's inductive probabilities or Schmeidler's non-additive probabilities.\footnote{ For more details, see \citet{Zadeh1978}, \citet{Dempster1967}, \citet{Shafer1976}, \citet{Shackle1949}, \citet{Cohen1977}, \citet{Schmeidler1989}.} A major motivation of these theorists has been that in cases where we have little or no evidence for or against \(p\), it should be reasonable to have low degrees of belief in each of \(p\) and ${\lnot}$\(p\), something apparently incompatible with the Bayesian approach. There are two broad types of response to this situation, the second of which shows the incompatibility just mentioned is more apparent than real. The first of these -- much in evidence in the work of the writers just cited -- is to replace or radically reconstrue the notion of probability taken by that approach to represent degrees of belief. The second -- to be defended here -- seeks to maintain the core of standard probability theory but to generalize the notion of a probability function to accommodate variation in the background logic of the account; this allows us to respond to such issues as the low degree of belief in a proposition and its negation by simply weakening the background logic from classical to intuitionistic logic. Thus if Bayesianism is construed as in our opening sentence, one way to respond to the objections of the heterodox writers listed above is to trade in \textit{classical} Bayesianism for \textit{intuitionistic} Bayesianism. Since for many theorists at least the motivation for their opposition to Bayesianism is grounded in either verificationism or anti-realism, a move to a intuitionistic theory of probability seems appropriate. Indeed, as \citet{Harman1983} notes, the standard analysis of degrees of belief as dispositions to bet leads naturally to a intuitionistic theory of probability. We give a Dutch Book argument in defence of constructive Bayesianism in Section 4 below.


The appropriate generalization of the notion of a probability function makes explicit allowance for a sensitivity to the background logic. The latter we identify with a consequence relation, such as, in particular, the consequence relation {\small \(\sststile{\mathrm{CL}}{}\)} associated with classical logic or the consequence relation {\small \(\sststile{\mathrm{IL}}{}\)} associated with intuitionistic logic. To keep things general, we assume only that the languages under discussion have two binary connectives: ${\vee}$ and ${\wedge}$. No assumptions are made about how a consequence relation on such a language treats compounds formed using these connectives, though of course in the cases in which we are especially interested, {\small \(\sststile{\mathrm{CL}}{}\)} and {\small \(\sststile{\mathrm{IL}}{}\)}, such compounds have the expected logical properties. We take the language of these two consequences relations to be the same, assuming in particular that negation (${\lnot}$) is present for both. Finally, if \(A\) belongs to the language of a consequence relation {\small \(\sststile{}{}\)}, then we say that \(A\) is a {\small \(\sststile{}{}\)}{}-\textit{thesis} of {\small \(\sststile{}{}\)} \(A\) and that \(A\) is a {\small \(\sststile{}{}\)}{}-\textit{antithesis} if for all \(B\) in that language \(A\) {\small \(\sststile{}{}\)} \(B\). (Thus the {\small \(\sststile{}{}\)}{}-theses and antitheses represent the logical truths and logical falsehoods as seen from the perspective of {\small \(\sststile{}{}\)}.) We are now in a position to give the key definition. 

If {\small \(\sststile{}{}\)} is a consequence relation, then a function \textit{Pr} mapping the language of {\small \(\sststile{}{}\)} to the real interval [0,1] is a {\small \(\sststile{}{}\)}\textit{{}-probability function} if and only if the following conditions are satisfied:

\begin{description}
\item[P0)]\textit{Pr}(\(A\)) = 0 if \(A\) is a {\small \(\sststile{}{}\)}{}-antithesis.
\item[(P1)]\textit{Pr}(\(A\)) = 1 if \(A\) is a {\small \(\sststile{}{}\)}{}-thesis
\item[(P2)]If \(A\)~{\small \(\sststile{}{}\)} \(B\) then \textit{Pr}(\(A\))~${\leq}$~\textit{Pr}(\(B\))
\item[(P3)]\textit{Pr}(\(A\))~+~\textit{Pr}(\(B\)) = \textit{Pr}(\(A\)~${\vee}$~\(B\))~+~\textit{Pr}(\(A\)~${\wedge}$~\(B\))
\end{description}


\noindent If {\small \(\sststile{}{}\)} is {\small \(\sststile{\mathrm{CL}}{}\)}, then we call a {\small \(\sststile{}{}\)}{}-probability function a \textit{classical probability function}; if {\small \(\sststile{}{}\)} is {\small \(\sststile{\mathrm{IL}}{}\)} we call a {\small \(\sststile{}{}\)}{}-probability function an \textit{intuitionistic} \textit{probability function}. The position described above as constructive Bayesianism would replace classical probability functions by intuitionistic probability functions as candidate representations of reasonable epistemic states. Note that classical probability functions in this sense are exactly those obeying the standard probability calculus axioms. In paricular, the familiar negation axiom dictating that \textit{Pr}(${\lnot}$\(A\)) = 1 -- \textit{Pr}(\(A\)) emerges as a by-product of the interaction between the general (i.e., logic-independent) condition (P3) and, via (P0) and (P1), the logic-specific facts that \(A\)~${\wedge}$~${\lnot}$\(A\) is a {\small \(\sststile{\mathrm{CL}}{}\)}{}-antithesis\textit{ }and \(A\)~${\vee}$~${\lnot}$\(A\) is a {\small \(\sststile{\mathrm{CL}}{}\)}{}-thesis for any \(A\).

Although it is these two kinds -- intuitionistic and classical -- of probability functions we shall be dealing with specifically in what follows, we emphasize the generality of the above definition of a {\small \(\sststile{}{}\)}{}-probability function, and invite the reader to consider what effect further varying the choice of {\small \(\sststile{}{}\)} has on the behaviour of such functions. Our attention will be on the comparative merits of {\small \(\sststile{\mathrm{CL}}{}\)} and {\small \(\sststile{\mathrm{IL}}{}\)} in this regard. (It may have occurred to the reader in connection with (P3) above that we might naturally have considered a generalized version of (P3) for `countable additivity'. Whether such a condition ought be adopted will turn on some rather difficult questions concerning the use of infinities in constructive reasoning; let us leave it as a question for further research. We have stated (P3) in its finitary form so as not to require that intuitionistic probability functions satisfy the more contentious general condition.)

In the following section we shall review some of the motivations for intuitionistic Bayesianism. The arguments are rather piecemeal; they are designed to show that given the philosophical commitments various writers in the field have expressed they would be better off taking this route, i.e., focussing on the class of intuitionistic probability functions, than -- as many of them have suggested --abandoning Bayesianism in our broad sense. In particular, we shall urge that moves in the latter direction which involve abandoning (what we shall call) the Principle of Addition are seriously undermotivated. 


One aspect of the Bayesian perspective which we have not considered concerns the dynamics rather than the statics of epistemic states: in particular the idea that changes in such states are governed for rational agents by the principle of conditionalizing on new information. This requires that we have a dyadic functor available for expressing conditional probabilities. Accordingly, where \textit{Pr} is for some consequence relation {\small \(\sststile{}{}\)} a {\small \(\sststile{}{}\)}{}-probability function, we favour the standard account and take the associated conditional {\small \(\sststile{}{}\)}{}-probability function \textit{Pr}( {\textperiodcentered} , {\textperiodcentered} ) to be given by \textit{Pr}(\(A\),\(B\)) = \textit{Pr}(\(A\)~${\wedge}$~\(B\))/\textit{Pr}(\(B\)) when \textit{Pr}(\(B\)) ${\neq}$ 0, with \textit{Pr}(\(A\),\(B\)) undefined when \textit{Pr}(\(B\)) = 0. The intention, of course, is that \textit{Pr}(\(A\),\(B\)) represents the conditional probability of \(A\) given \(B\). We defer further consideration of conditional probability until the Appendix.


\section{Motivating Intuitionistic Bayesianism}
There are four main reasons for grounding preferring intuitionistic over classical probability functions as representing the range of reasonable epistemic states. These are: (1) a commitment to verificationism, (2) a commitment to anti-realism, (3) preservation of the principle of Addition, and (4) avoidance of direct arguments for the orthodox approach. Now some of these will be viewed by some people as bad reasons for adopting the given position, a reaction with which it is not hard to sympathise. In particular, the verificationist and anti-realist elements of the theory might well be viewed as negatives. These arguments are principally directed at showing that by their own lights, various opponents of classical Bayesianism would do better to adopt the intuitionistic Bayesian position than some still more heterodox non-Bayesian account.


\textbf{2.1 }A standard objection to classical Bayesianism is that it has no way of representing complete uncertainty. Because of the failures of Laplace's principle of indifference, it can't be said that uncertainty about \(p\) is best represented by assigning credence 1/2 to \(p\). Heterodox approaches usually allow the assignment of credence 0 to both \(p\) and ${\lnot}$\(p\) when an agent has no evidence at all as to whether or not \(p\) is true. Because these approaches generally require an agent to assign credence 1 to classical tautologies, including \(p\)~${\vee}$~${\lnot}$\(p\), these theories must give up the following \textit{Principle of Addition}.

\begin{description}
\item[\textit{Addition}] For incompatible \(A\), \(B\): \textit{Bel}(\(A\)~${\vee}$~\(B\))~=~\textit{Bel}(\(A\))~+~\textit{Bel}(\(B\)).
\end{description}

\noindent ``\textit{Bel}(\(A\))'' is here used to mean the degree of belief the agent has in \(A\), and ``incompatible'' to apply to \(A\) and \(B\) in which for some favoured consequence relation {\small \(\sststile{}{}\)}, the conjunction of \(A\) with \(B\) is a {\small \(\sststile{}{}\)}{}-antithesis. Such conditions as Addition are of course taken not as descriptive theories about all agents, since irrational agents would serve as counterexamples. Rather, they are proposed coherence constraints on all rational agents.

The Principle of Addition is stated in terms of degrees of belief, or credences. Where no ambiguity results we also use the same term to refer to the corresponding principle applied to {\small \(\sststile{}{}\)}{}-probability functions, with incompatibility understood in terms of {\small \(\sststile{}{}\)} (as just explained). Now in some writings (particularly Shafer's) the reason suggested for giving up \textit{Addition} is openly verificationist. Shafer says that when an agent has no evidence for \(p\), they should assign degree of belief 0 to \(p\). Degrees of belief, under this approach, must be proportional to evidence.\footnote{This assumption was shared by many of the participants in the symposium on probability in legal reasoning, reported in the Boston University Law Review 66 (1986).} In recent philosophical literature, this kind of verificationism is often accompanied by an insistence that validity of arguments be judged by the lights of {\small \(\sststile{\mathrm{IL}}{}\)} rather than {\small \(\sststile{\mathrm{CL}}{}\)}.

A similar line of thought is to be found in \citet{Harman1983}. He notes that when we don't distinguish between the truth conditions for a sentence and its assertibility conditions, the appropriate logic is intuitionistic. And when we're considering gambles, something like this is correct. When betting on \(p\) we don't, in general, care if \(p\) is true as opposed to whether it will be discovered that \(p\) is true. A \(p\)\nobreakdash-bet, where \(p\) asserts the occurrence of some event for instance, becomes a winning bet, not when that event occurs, but when \(p\) becomes assertible. So perhaps not just verificationists like Shafer, but all those who analyse degrees of belief as propensity to bet should adopt constructivist approaches to probability.

To see the point Harman is making, consider this example. We are invited to quote for \(p\)\nobreakdash-bets and ${\lnot}$\(p\)\nobreakdash-bets, where \(p\) is \textit{O. J. Simpson murdered his wife}. If we are to take the Californian legal system literally, the probability of that given the evidence is strictly between one-half and one. To avoid one objection, these bets don't just pay \$1 if the bettor guesses correctly. Rather they pay \$1 invested at market rates of interest at the time the bet is placed. The idea is that if we pay \textit{x} cents for the bet now, when it is discovered that we have bet correctly we will receive a sum of money that is worth exactly as much as \$1 now. Still, we claim, it might be worthwhile to quote less than 50 cents for each of the bets. Even if we will receive \$1 worth of reward if we wager correctly, there is every possibility that we'll never find out. So it might be that placing a bet would be a losing play either way. To allow for this, the sum of our quotes for the \(p\)\nobreakdash-bet and the ${\lnot}$\(p\)\nobreakdash-bet may be less than \$1. As Harman points out, to reply by wielding a Dutch Book argument purporting to show that this betting practice is incoherent would be blatantly question-begging. That argument simply assumes that \(p\)~${\vee}$~${\lnot}$\(p\) is a logical truth, which is presumably part of what's at issue. (In our terminology, this disjunction has the status of a {\small \(\sststile{\mathrm{CL}}{}\)}{}-thesis which is not a {\small \(\sststile{\mathrm{IL}}{}\)}{}-thesis.)

Harman's point is not to argue for a intuitionistic approach to probability. Rather, he is arguing against using probabilistic semantics for propositional logic. Such an approach he claims would be bound to lead to intuitionistic logic for the reasons given above. He thinks that, since this would be an error, the move to probabilistic semantics is simply misguided. Whatever we think of this conclusion, we can press into service his arguments for intuitionistic Bayesianism.

\textbf{2.2} The second argument for this approach turns on the anti-realism of some heterodox theorists. So George Shackle, for example, argues that if we are anti-realists about the future, we will assign positive probability to no future-directed proposition. The following summary is from a sympathetic interpreter of Shackle's writing.

\begin{quote}
[T]here is every reason to refuse additivity: [it] implies that the certainty that would be assigned to the set of possibilities should be `distributed' between different events. Now this set of events is undetermined as the future -- that exists only in imagination -- is. \cite[171]{Ponsonnet1996}
\end{quote}

\noindent Shackle's anti-realism is motivated by what most theorists would regard as a philosophical howler: he regards realism about the future as incompatible with human freedom, and holds that human beings are free. The second premise here seems harmless enough, but the first is notoriously difficult to motivate. Nevertheless, there are some better arguments than this for anti-realism about the future. If we adopt these, it isn't clear why we should `assign certainty' to the set of possibilities.

Shackle is here assuming that for any proposition \(p\), even a proposition about the future, \(p\)~${\vee}$~${\lnot}$\(p\) is now true, although neither disjunct is true. Given his interests it seems better to follow Dummett here and say that if we are anti-realists about a subject then for propositions \(p\) about that subject, \(p\)~${\vee}$~${\lnot}$\(p\) fails to be true. Hence we have no need to `assign certainty to the set of possibilities'. Or perhaps more accurately, assigning certainty to the set of possibilities does not mean assigning probability 1 to \(p\)~${\vee}$~${\lnot}$\(p\); in particular, condition (P1) on {\small \(\sststile{}{}\)}{}-probability functions does not require this when we choose {\small \(\sststile{}{}\)} as {\small \(\sststile{\mathrm{IL}}{}\)}.

\textbf{2.3} The third motivation for adopting an intuitionistic approach to probability is that it allows us to retain the Kolmogorov axioms for probability, in particular the Principle of Addition. This principle has, to my mind at least, some intuitive motivation. And the counterexamples levelled against it by heterodox theorists seem rather weak from the intuitionistic Bayesian perspective. For they all are cases where we might feel it appropriate to assign a low probability to a proposition and its negation\footnote{Again the discussion in \cite[ch. 2]{Shafer1976} is the most obvious example of this, but similar examples abound in the literature.}. Hence if we are committed to saying \textit{Pr}(\(A\)~${\vee}$~${\lnot}$\(A\))~=~1 for all \(A\), we must give up the Principle of Addition. But the intuitionistic Bayesian simply denies that in these cases \textit{Pr}(\(A\)~${\vee}$~${\lnot}$\(A\))~=~1, so no counterexample to Addition arises. This denial is compatible with condition (P1) on \textit{Pr}'s being a {\small \(\sststile{\mathrm{IL}}{}\)}{}-probability function since, as already noted, \(A\)~${\vee}$~${\lnot}$\(A\) is not in general a {\small \(\sststile{\mathrm{IL}}{}\)}\textit{{}-}thesis\textit{.}

\textbf{2.4} The final argument for taking an intuitionistic approach is that it provides a justification for rejecting the positive arguments for classical Bayesianism. These provide a justification for requiring coherent degrees of belief to be representable by the classical probability calculus. There are a dizzying variety of such arguments which link probabilistic epistemology to decision theory, including: the traditional Dutch Book arguments found in \citet{RamseyTruthProb}, \citet{Teller1973} and \citet{Lewis1999b}; de-pragmatized Dutch Book arguments which rely on consistency of valuations, rather than avoiding actual losses, as in \citet{HowsonUrbach1989}, \citet{Christensen1996} and \citet{Hellman1997}; and arguments from the plausibility of decision theoretic constraints to constraints on partial beliefs, as in \citet{Savage1954}, \citet{Maher1993} and \citet{Kaplan1996}. As well as these, there are arguments for classical Bayesianism which do not rely on decision theory in any way, but which flow either directly from the definitions of degrees of belief, or from broader epistemological considerations. A summary of traditional arguments of this kind is in \citet{Paris1994}. \citet{Joyce1998} provides an interesting modern variation on this theme.

All such arguments assume classical -- rather than, say, intuitionistic -- reasoning is appropriate. The intuitionist has a simple and principled reason for rejecting those arguments. The theorist who endorses {\small \(\sststile{\mathrm{CL}}{}\)} when considering questions of inference, presumably lacks any such simple reason. And they need one, unless they think it appropriate to endorse one position knowing there is an unrefuted argument for an incompatible viewpoint.

We are not insisting that non-Bayesians will be unable to refute these arguments while holding on to {\small \(\sststile{\mathrm{CL}}{}\)}. We are merely suggesting that the task will be Herculean. A start on this project is made by \citet{Shafer1981}, which suggests some reasons for breaking the link between probabilistic epistemology and decision theory. Even if these responses are successful, such a response is completely ineffective against arguments which do not exploit such a link. As we think these are the strongest arguments for classical Bayesianism, non-Baeyesians have much work left to do. And it is possible that this task cannot be completed. That is, it is possible that the only questionable step in some of these arguments for classical Bayesianism is their use of non-constructive reasoning. If this is so only theorists who give up {\small \(\sststile{\mathrm{CL}}{}\)} can respond to such arguments.

In sum, non-Bayesians need to be able to respond to the wide variety of arguments for Bayesianism. Non-Bayesians who hold on to {\small \(\sststile{\mathrm{CL}}{}\)} must do so without questioning the implicit logical assumptions of such arguments. Given this restriction, producing these responses will be a slow, time-consuming task, the responses will in all likelihood be piecemeal, providing little sense of the underlying flaw of the arguments, and for some arguments it is possible that no effective response can be made. Intuitionistic Bayesians have a quick, systematic and, we think, effective response to all these arguments.

\section{More on Intuitionistic Probability Functions}
Having explained the motivation for intuitionistic Bayesianism, let us turn our attention in greater detail to its main source of novelty: the intuitionistic probability functions. We concentrate on logical matters here, in the following section justifying the singling out of this class of probability functions by showing that an epistemic state represented by \textit{Bel} is invulnerable to a kind of Dutch Book if and only if \textit{Bel} is an intuitionistic probability function. 

For the case of specifically \textit{classical} probability functions, the conditions (P0)--(P4) of Section 1 involve substantial redundancy. For example, we could replace (P2) and (P3) by -- what would in isolation be weaker conditions -- (P2\(^\prime\)) and (P3\(^\prime\)).

\begin{description}
\item[(P2\(^\prime\))]If \(A\) {\small \(\nsststile{}{}\)}~{\small \(\sststile{}{}\)} \(B\) then \textit{Pr}(\(A\)) = \textit{Pr}(\(B\))
\item[(P3\(^\prime\))]If {\small \(\sststile{}{}\)} ${\lnot}$(\textit{A }${\wedge}$\textit{ B}) then \textit{Pr}(\(A\)~${\vee}$~\(B\)) = \textit{Pr}(\(A\)) + \textit{Pr}(\(B\))
\end{description}

\noindent However, in the general case of arbitrary {\small \(\sststile{}{}\)}{}-probability functions (or rather: those for which ${\lnot}$ is amongst the connectives of the language of {\small \(\sststile{}{}\)}), such a replacement would result in a genuine weakening, as we may see from a consideration of the class of {\small \(\sststile{\mathrm{IL}}{}\)}{}-probability functions. While both (P2\(^\prime\)) and (P3\(^\prime\)) are satisfied for {\small \(\sststile{}{}\)} as {\small \(\sststile{\mathrm{IL}}{}\)}, the class of functions \textit{Pr} satisfying (P0), (P1), (P2\(^\prime\)) and (P3\(^\prime\)) is broader (for this choice of {\small \(\sststile{}{}\)}) than the class of intuitionistic probability functions. To see this, first note that the function \textit{P}, defined immediately below, satisfies (P0), (P1), (P2) and (P3\(^\prime\)), but not (P3).

\begin{equation}
P(A) = 
\begin{cases}
1 \text{ if } p \vee q~ \sststile{\mathrm{IL}}{}~ A \\
0 \text{ otherwise}
\end{cases}
\end{equation}

\noindent (Here \(p\) and \textit{q} are a pair of atomic sentences.) To see that (P3\(^\prime\)) is satisfied, assume \textit{P}(\(A\)~${\vee}$~\(B\)) = 1 and {\small \(\sststile{\mathrm{IL}}{}\)} ${\lnot}$(\textit{A~}${\wedge}$~\(B\)). Then \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~${\vee}$~\(B\), and \(B\)~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\). Hence \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~${\vee}$~${\lnot}$\(A\), but this only holds if either (1) \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\) or (2) \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\). (For if \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~${\vee}$~${\lnot}$\(A\), then \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~${\vee}$~${\lnot}$\(A\) and~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~${\vee}$~${\lnot}$\(A\), whence by a generalization, due to Harrop, of the Disjunction Property for intuitionistic logic, either \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~or \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\) and similarly either \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\)~or \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\). Thus one of the following four combinations obtains: (a) \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\textit{A }and \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\), (b) \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\) and \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\), (c) \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\) and \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\), (d) \(p\)~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\) and \textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~${\lnot}$\(A\). But cases (b) and (c) can be ruled out since they would make \(p\) and \textit{q} {\small \(\sststile{\mathrm{IL}}{}\)}{}-incompatible, contradicting their status as atomic sentences, and from (a) and (d), (1) and (2) follow respectively.) If (1) first holds then \textit{P}(\(A\)) = 1, as required. If (2) holds then \(p\)~${\vee}$~\textit{q}~{\small \(\sststile{\mathrm{IL}}{}\)}~(\(A\)~${\vee}$~\(B\))~${\wedge}$~${\lnot}$\(A\)~and (\(A\)~${\vee}$~\(B\))~${\wedge}$~${\lnot}$\(A\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\(B\), so \textit{P}(\(B\)) = 1. The other cases are trivial to verify and are left to the reader.

To see (P2) is needed (for the current choice of {\small \(\sststile{}{}\)}), as opposed to just (P2\(^\prime\)), consider the following Kripke tree.

\ConProbKripkeTree

\noindent We introduce a ``weighting'' function \textit{w} by setting \textit{w}(1) = 0.2, \textit{w}(2) = 0.3, \textit{w}(3) = -0.1 and \textit{w}(4)~=~0.6. For any \(A\), let \textit{P}(\(A\))~=~${\Sigma}$\textit{w}(\textit{i}), where the summation is across all points \textit{i} that force \(A\). So \textit{P}(\(p\))~= 0.6 and \textit{P}(${\lnot}{\lnot}$\(p\)) = 0.5, contradicting (P2). But (P0), (P1), (P2\(^\prime\)) and (P3) are all satisfied, showing that (P2) is in the general case not derivable from these three conditions.

\section{Bets and Intuitionistic Probability Functions}
Say that an \(A\)\nobreakdash-bet is a bet that pays \$1 if \(A\) and nothing otherwise. These will sometimes be called bets on \(A\). In this theory, as in real life, it is possible that neither \(A\)\nobreakdash-bets nor ${\lnot}$\(A\)\nobreakdash-bets will ever be collected, so holding an \(A\)\nobreakdash-bet and a ${\lnot}$\(A\)\nobreakdash-bet is not necessarily as good as holding \$1. An \(A\)\nobreakdash-bet becomes a winning bet, i.e. worth \$1, just when it becomes known that \(A\). We will assume that bookmakers and punters are both logically proficient and honest, so that when a \(B\)\nobreakdash-bet becomes a winning bet and \(B\) {\small \(\sststile{\mathrm{IL}}{}\)} \(A\), then an \(A\)\nobreakdash-bet is a winning bet. The picture underlying this story is the Kripke tree semantics for intuitionistic logic. Bettors are thought of as being at some node of a Kripke tree, an \(A\)\nobreakdash-bet wins at that stage iff \(A\) is forced by that node. Bettors do not know that any future nodes will be reached, so they cannot be confident that all bets on classical tautologies ({\small \(\sststile{\mathrm{CL}}{}\)}{}-theses) will be winning. And more importantly, we take it that an (\(A\)~${\vee}$~\(B\))\nobreakdash-bet wins if and only if an \(A\)\nobreakdash-bet wins or a \(B\)\nobreakdash-bet wins. Again this mirrors the fact that \(A\)~${\vee}$~\(B\) is forced at a node iff \(A\) is forced or \(B\) is forced.

Finally, to get the Dutch Book style argument going, assume that for any sequence of bets on \(A\)\textsubscript{1}, \(A\)\textsubscript{2}, ..., \(A\)\textit{\textsubscript{k}}, the bettor values the sequence at \$(\textit{Bel}(\(A\)\textsubscript{1}) + \textit{Bel}(\(A\)\textsubscript{2}) + ... + \textit{Bel}(\(A\)\textit{\textsubscript{k}})). This is obviously unrealistic and economically suspect\footnote{ It is economically suspect because, in simplified terms, \textit{Bel}(\(A\)) gives at best the use-value of an \(A\)\nobreakdash-bet, but this is distinct from the exchange\nobreakdash-value the agent places on the bet. And it is the exchange-value that determines her patterns of buying and selling.}, but is perhaps a useful analogy. Then \textit{Bel} leads to coherent valuations in all circumstances iff \textit{Bel} is a intuitionistic probability function. That is, if \textit{Bel} is not an intuitionistic probability function (henceforth: IPF) then there will be two finite sequences of bets \textit{S}\textsubscript{1} and \textit{S}\textsubscript{2} such that \textit{S}\textsubscript{1} is guaranteed to pay at least as much as \textit{S}\textsubscript{2} in all circumstances, but \textit{S}\textsubscript{2} is given higher value by the agent. For simplicity \textit{Bel} will be called incoherent if this happens, and coherent otherwise. If \textit{Bel} is an IPF there are no two such sequences, so it is coherent.

If \textit{Bel} is not an IPF then we just need to look at which axiom is breached in order to construct the sequences. For example, if (P3) is breached then let the sequences be {{\(\langle\)}}\(A\), \(B\){{\(\rangle\)}} and {{\(\langle\)}}\(A\)~${\vee}$~\(B\),~\textit{A~}${\wedge}$~\(B\){{\(\rangle\)}}. The same number of propositions from each sequence are forced at every node of every Kripke tree, so the coherence requirement is that the two sequences receive the same value. But \textit{ex hypothesi} they do not, so \textit{Bel} is incoherent. Similar proofs suffice for the remaining axioms (the remaining conditions on {\small \(\sststile{}{}\)}{}-probability functions, that is,\textit{ }as they apply in the special case of {\small \(\sststile{}{}\)} = {\small \(\sststile{\mathrm{IL}}{}\)}).

To show that if \textit{Bel} is an IPF it is coherent, we need some more notation. Let {\(\langle\)}\(A\)\textsubscript{1}, ..., \(A\)\textit{\textsubscript{k}}{\(\rangle\)} be a sequence of propositions. Then say \textit{c}\textit{\textsubscript{n}}\textsubscript{, }\textit{\textsubscript{k}} is the proposition true iff at least \textit{n} of these are true. So \textit{c}\textsubscript{2,3} is the proposition (\(A\)\textsubscript{1}~${\wedge}$~\(A\)\textsubscript{2}) ${\vee}$ (\(A\)\textsubscript{1}~${\wedge}$~\(A\)\textsubscript{3})~${\vee}$~(\(A\)\textsubscript{2}~${\wedge}$~\(A\)\textsubscript{3}). Assuming \textit{Bel} is a IPF, we prove the following lemma holds for all \textit{k}:
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\begin{flalign}
&\textit{Lemma:} ~~\sum^{k}_{i = 1}\textit{Bel}(A_i) = \sum^{k}_{i = 1}\textit{Bel}(c_{i,k})&  
\end{flalign}
The proof is by induction on \textit{k}. For \textit{k}=1 and \textit{k}=2, the proof is given by the axioms. So it remains only to complete the inductive step. For ease of reading in the proof we write \(A\) for \textit{Bel}(\(A\)) where no ambiguity would result.

By the inductive hypothesis we have:
\begin{flalign}
k\sum^{k+1}_{i=1}A_i &= k\sum^{k}_{i=1}c_{i,k}+kA_{k+1} \\
 &=(k-1)\sum^{k}_{i=1}c_{i,k} +  \sum^{k}_{i=1}c_{i,k} + kA_{k+1} \\
 &=(k-1)\sum^{k}_{i=1}c_{i,k} + \sum^{k}_{i=1}(c_{i,k} \vee A_{k+1}) + (c_{i,k} + A_{k+1}) & \text{by $k$ applications of (P3)} 
\end{flalign}
\begin{flalign}
&\text{Since }\sum^{k+1}_{i=1}A_i = \sum^{k}_{i=1} + A_{k+1} = \sum^{k}_{i=1}c_{i,k} + A_{k+1} \text{, this equation simplifies to} &{}
\end{flalign}
\smallskip
\begin{flalign}
&\sum^{k+1}_{i=1} A_i+ (k-1)A_{k+1} = \sum^{k}_{i=1}(c_{i,k} \vee A_{k+1}) + (c_{i,k} + A_{k+1}) &{}
\end{flalign}

\medskip
\noindent Since \(c_{i,k} \vee A_{k+1}\) {\small \(\nsststile{}{}\)}~{\small \(\sststile{}{}\)} \(c_{i,k+1} \vee A_{k+1}\) and \(c_{i,k} \wedge A_{k+1}\) {\small \(\nsststile{}{}\)}~{\small \(\sststile{}{}\)} \(c_{i+1,k+1} \wedge A_{k+1}\) we have:
\begin{flalign}
&\sum^{k+1}_{i=1} A_i+ (k-1)A_{k+1} = \sum^{k}_{i=1}(c_{i,k+1} \vee A_{k+1}) + \sum^{k}_{i=1}(c_{i+1,k+1} \wedge A_{k+1})&{}
\end{flalign}

\noindent Now, \(c_{1,k+1} \vee~ A_{k+1}\) {\small \(\nsststile{}{}\)}~{\small \(\sststile{}{}\)} \(c_{i,k+1}\) and \(c_{k+1,k+1} ~\wedge~ A_{k+1}\) {\small \(\nsststile{}{}\)}~{\small \(\sststile{}{}\)} \(c_{k+1,k+1}\) from the definitions of \(c\). So substituting in these equivalences and slightly renumbering, we get:
\begin{flalign}
&\sum^{k+1}_{i=1} A_i+ (k-1)A_{k+1} = c_{i,k+1} + c_{k+1,k+1} + \sum^{k-1}_{i=1}(c_{i,k+1} \vee A_{k+1}) + \sum^{k-1}_{i=1}(c_{i+1,k+1} \wedge A_{k+1})&{}
\end{flalign}
Regrouping the last two summations and applying (P3),
\begin{flalign}
\sum^{k+1}_{i=1} A_i+ (k-1)A_{k+1} &= c_{i,k+1} + c_{k+1,k+1} + \sum^{k-1}_{i=1}c_{i+1,k+1} + A_{k+1} &~\\
{} &=\sum^{k+1}_{i=1}c_{i,k+1}+(k-1)A_{k+1} &~
\end{flalign}
And cancelling out the second term on each side gives us the result we want. From this it follows immediately that \textit{Bel} is coherent. Let \textit{S}\textsubscript{1} and \textit{S}\textsubscript{2} be any two sequences such that \textit{S}\textsubscript{1} is guaranteed to pay as much as \textit{S}\textsubscript{2}. That is, that \textit{S}\textsubscript{2} pays \$\textit{n} entails \textit{S}\textsubscript{1} pays at least \$\textit{n} for all \textit{n}. Now the lemma shows that for each sequence of bets, their value equals the sum of the probability that they'll pay at least \textit{n} for all values of \textit{n}, up to the length of the sequence. So by as many appeals to (P2) as there are bets in \textit{S}\textsubscript{1}, we have that the value of \textit{S}\textsubscript{2} is less than or equal to the value of \textit{S}\textsubscript{1}, as required.
\setlength{\abovedisplayskip}{10pt plus 2pt minus 5pt}
\setlength{\belowdisplayskip}{10pt plus 2pt minus 5pt}

Given the well-known problems with Dutch Book arguments\footnote{ See \citet{Maher1993} for criticisms of the most recent attempts at successful Dutch Book arguments and references to criticisms of earlier attempts.}, it might be wondered if we can give a different justification for the axioms. Indeed it may be considered helpful to have a semantics for the logic which does not refer to betting practices. One possibility is to say that IPFs are normalised measures on Kripke trees. The idea is that the probability of a proposition is the measure of the set of points at which the proposition is forced. It is straightforward to give a non-constructive proof that the axioms are sound with respect to these semantics, but making this proof constructive and providing any proof that the axioms are complete is a harder task. So for now this Dutch Book justification for the axioms is the best available.

\section*{Appendix: The Morgan--Leblanc--Mares Calculus}
In a series of papers (\citet{MorganLeBlanc1983a, MorganLeBlanc1983b}, \citet{MorganMares1995}) an approach to probability grounded in intuitionistic logic has been developed. The motivation is as follows. A machine contains an unknown set of propositions \textit{S}, which need not be consistent. \textit{Pr}(\(A\), \(B\)) is the maximal price we'd pay for a bet that \textit{S} and \(B\) intuitionistically entail \textit{A }(\textit{S},~\textit{A }{\small \(\sststile{\mathrm{IL}}{}\)}\textit{ B}, that is). By standard Dutch Book arguments, we obtain axioms for a probability calculus which has some claim to being constructivist. The point of this section is to register the shortcomings of this approach as a theory of uncertain reasoning from evidence -- to point out, that is, the implausibility of interpreting the axioms they derive as normative constraints on degrees of belief. (It should be noted from the start that this was \textit{not} the advertised purpose of their theory, and at least one of the authors (Mares) has said (p.c.) that the primary purpose of constructing these theories was to generalise of the triviality results proved in \citet{Lewis1976b}. So the purpose of this appendix may be to argue for something that isn't in dispute: that these theories can't be pushed into double duty as theories of reasoning under uncertainty.)


The axiomatisations given in the Morgan and Leblanc papers differs a little from that given in the Morgan and Mares paper, but the criticisms levelled here apply to their common elements. In particular, the following four axioms are in both sets.

\begin{description}
\item[(C1)] 0 ${\leq}$ \textit{Pr}(\(A\), \(B\))~${\leq}$~1
\item[(C2)] \textit{Pr}(\(A\), \(A\)~${\wedge}$~\(B\)) = 1
\item[(C3)]\textit{Pr}(\(A\), \(B\)~${\wedge}$~\textit{C})~{\textperiodcentered} \textit{Pr}(\(B\), \textit{C}) = \textit{Pr}(\(B\), \(A\)~${\wedge}$~\textit{C})~{\textperiodcentered} \textit{Pr}(\(A\), \textit{C})
\item[(C4)]\textit{Pr}(\(A\)~${\supset}$~\(B\), \textit{C}) = \textit{Pr}(\(B\), \(A\)~${\wedge}$~\textit{C})
\end{description}

\noindent These four are enough to get both the unwanted consequences. In particular, from these we get the `no negative evidence' rule: \textit{Pr}(\(A\), \(B\)~${\wedge}$~\textit{C})~${\geq}$ \textit{Pr}(\(A\), \(B\)). The proof is in \citet{MorganMares1995} Now given the semantic interpretation they have adopted, this is perhaps not so bad. After all, if we can prove \(A\) from \(B\) and \textit{S}, we can certainly prove it from \(B\)~${\wedge}$~\textit{C} and \textit{S}, but the converse does not hold. However from our perspective this feature seems a little implausible. In particular, if \textit{C} is ${\lnot}$\(A\), it seems we should have \textit{Pr}(\(A\), \(B\)~${\wedge}$~${\lnot}$\(A\)) = 0 unless \(B\)~{\small \(\sststile{\mathrm{IL}}{}\)}~\(A\), in which case \textit{Pr}(\(A\),~\(B\)~${\wedge}$~${\lnot}$\(A\)) is undefined.

It shouldn't be that surprising that we get odd results given (C4). \citet{Lewis1976b} shows that adopting it for a (primitive or defined) connective `${\rightarrow}$' within the classical probability calculus leads to triviality. And neither the arguments he uses there nor the arguments for some stronger conclusions in \citet{Lewis1999b} rely heavily on classical principles. The papers by Morgan and Leblanc don't discuss this threat, but it is taken discussed in detail in \citet{MorganMares1995}. Morgan and Mares note that it's possible to build a theory based on (C1) to (C4) that isn't trivial in the sense Lewis described. But these theories still have enough surprising features that they aren't suitable for use as a theory of reasoning under uncertainty.

In intuitionistic logic we often take the falsum ${\perp}$ as a primitive connective, functioning as a {\small \(\sststile{\mathrm{IL}}{}\)}\nobreakdash-antithesis. Hence a set \textit{S }is intuitionistically consistent iff we do not have \textit{S} {\small \(\sststile{\mathrm{IL}}{}\)} ${\perp}$. Now the following seems a plausible condition:

\begin{description}
\item[(C${\perp}$)]For consistent \(B\), \textit{Pr}(${\perp}$, \(B\)) = 0.
\end{description}

\noindent Given consistent evidence, we have no evidence at all that the falsum is true. Hence we should set the probability of the falsum to 0 (as required by our condition (P0) from Section 1). Given Morgan and Leblanc's original semantic interpretation there is less motivation for adopting (C${\perp}$), since \textit{S} might be inconsistent. The restriction to consistent \(B\) in (C${\perp}$) is imposed because we take \textit{Pr}(\(A\), \(B\)) to be undefined for inconsistent \(B\), as explained at the end of Section 1. (In more detail: if \(B\) is a {\small \(\sststile{\mathrm{IL}}{}\)}{}-antithesis then \textit{Pr}(\(B\)) = 0 for any intuitionistic probability function \textit{Pr}, whence the undefinedness of \textit{Pr}(\(A\), \(B\)) by the remarks at the end of that section.) Morgan, Leblanc and Mares take it to be set at 1. The choice here is a little arbitrary, the only decisive factor being apparently the easier statement of certain results. Now if we take the falsum as a primitive the next move is usually to introduce ${\lnot}$ as a defined connective, as follows.

\begin{description}
\item ${\lnot}$\(A\)~=\textsubscript{df} \(A\)~${\supset}$~${\perp}$
\end{description}

\noindent Assuming \(A\) ${\wedge}$ \textit{B }is consistent, it follows from (C4) and (C${\perp}$) that \textit{Pr}(${\lnot}$\(A\), \(B\)) = 0. Again, from our perspective this is an implausible result. The main purpose of this appendix has been to show that the Morgan--Leblanc--Mares probability calculus cannot do the work Bayesians want a probability calculus to do. That is, it is implausible to regard their \textit{Pr}(\(A\), \(B\)) as the reasonable degree of belief in \(A\) given \(B\). Hence the account of conditional probability these authors offer diverges from the intuitionistic Bayesianism that we have been urging heterodox theorists to endorse.
