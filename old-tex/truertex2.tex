%
%
%
%
%
%%%%%%%%%%%%%%%%%%
%True, Truer, Truest
%%%%%%%%%%%%%%%%%%
%
%
%
%
%
\chapter{True, Truer, Truest}

\pubdata{\textit{Philosophical Studies} 123 (2005): 47-70. Thanks to audiences at the 2002 APA Central, Edinburgh and especially the 2003 BSPC for helpful comments. From the latter I'm especially grateful to Jonathan Bennett, Alex Byrne, Cian Dorr, Andy Egan, Elizabeth Harman, Robin Jeshion, Mike Nelson, Jonathan Schaffer, Ted Sider and Gabriel Uzquiano. I'm also grateful to two very helpful referee reports.}

What the world needs now is another theory of vagueness. Not because the old theories are useless. Quite the contrary, the old theories provide many of the materials we need to construct the truest theory of vagueness ever seen.  The theory shall be similar in motivation to supervaluationism, but more akin to many-valued theories in conceptualisation. What I take from the many-valued theories is the idea that some sentences can be \textit{truer} than others. But I say very different things to the ordering over sentences this relation generates. I say it is not a linear ordering, so it cannot be represented by the real numbers. I also argue that since there is higher-order vagueness, any mapping between sentences and mathematical objects is bound to be inappropriate. This is no cause for regret; we can say all we want to say by using the comparative \textit{truer than} without mapping it onto some mathematical objects. From supervaluationism I take the idea that we can keep classical logic without keeping the familiar bivalent semantics for classical logic. But my preservation of classical logic is more comprehensive than is normally permitted by supervaluationism, for I preserve classical inference rules as well as classical sequents. And I do this without relying on the concept of acceptable precisifications as an unexplained explainer. 

The world does not need another guide to varieties of theories of vagueness, especially since Timothy \citet{Williamson1994-WILV} and Rosanna \citet{Keefe2000} have already provided quite good guides. I assume throughout familiarity with popular theories of vagueness.

\section{Truer}
The core of my theory is that some sentences involving vague terms are truer than others. I won't give an analysis of \textit{truer}, instead I will argue that we already tacitly understand this relation. The main argument for this will turn on a consideration of two `many-valued' theories of vagueness, one of which will play a central role (as the primary villain) in what follows.

The most familiar many-valued theory, call it \(M\), says there are continuum many truth values, and they can be felicitously represented by the interval \([0,~1]\). The four main logical connectives: \textit{and}, \textit{or}, \textit{if} and \textit{not} are truth-functional. The functions are: 

\begin{align}
V(A \wedge B) &= min(V(A), V(B))  \hspace*{\fill} \\
V(A \vee B) &= max(V(A), V(B))  \hspace*{\fill} \\
V(A \rightarrow B) &= max(1, 1 - V(A) + V(B))  \hspace*{\fill} \\
V(\neg A) &= 1 - V(A)
\end{align} 

%\(V\)(\(A \wedge B\)) = \textit{min}(\(V\)(\(A\)), \(V\)(\(B\)))
%
%\(V\)(\(A \vee B\)) = \textit{max}(\(V\)(\(A\)), \(V\)(\(B\)))
%
%\(V\)(\(A \rightarrow B\)) = \textit{min}(1, 1 - \(V\)(\(A\)) + \(V\)(\(B\)))
%
%\(V\)(\(\neg A\)) = 1 - \(V\)(\(A\))
%

\noindent where \(V\) is the valuation function on sentences, \(min(x, y)\) is the smaller of \(x\) and \textit{y }and \(max(x, y)\) is the larger of \(x\) and \textit{y}.

Adopting these rules for the connectives commits us to adopting the logic {\L}\textsubscript{C}. \(M\) is the theory that this semantic model, under its most natural interpretation, is appropriate for vague natural languages. (We'll discuss less natural interpretations presently.) 

\(M\) tells a particularly nice story about the Sorites. A premise like \textit{If she's rich, someone with just a little less money is also rich} will have a very high truth value. If we make the difference in money between the two subjects small enough, this conditional will have a truth value arbitrarily close to 1. 

\(M\) also tells a nice story about borderline cases and determinateness. An object \(a\) is a borderline case of being an \(F\) just in case the sentence \textit{a is F} has a truth value between 0 and 1 exclusive. Similarly, \(a\) is a determinate \(F\) just in case the truth value of \textit{a is F} is 1. (It is worthwhile comparing how simple this analysis of determinateness is to the difficulties supervaluationists have in providing an analysis of determinateness. On this topic, see \citet{Williamson1995}, \citet{McGee1998} and \citet{Williamson2004-WILRTM}.)

But \(M\) tells a particularly implausible story about contradictions. Here is how Timothy \citet{Williamson1994-WILV} makes this problem vivid.

\begin{quote}
More disturbing is that the law of non-contradiction fails {\dots}. \(\neg(p \wedge \neg p)\)  always has the same degree of truth as \(p \vee \neg p\), and thus is perfectly true only when \(p\) is either perfectly true or perfectly false. When \(p\) is half-true, so are both \(p \wedge \neg p\) and \(\neg(p \wedge \neg p)\). \cite[118]{Williamson1994-WILV} 

At some point [in waking up] `He is awake' is supposed to be half-true, so `He is not awake' will be half-true too. Then `He is awake and he is not awake' will count as half-true. How can an explicit contradiction be true to any degree other than 0? \cite[136]{Williamson1994-WILV} 
\end{quote}

\noindent There is a way to keep the semantic engine behind \(M\) while avoiding this consequence. (The following few paragraphs are indebted pretty heavily to the criticisms of Strawson's theory of descriptions in \citet{Dummett1959})

Consider an interpretation of the above semantics on which there are only two truth values: True and False. Any sentence that gets truth value 1 is true, all the others are false. The numbers in [0, 1) represent different ways of being false. (As Tolstoy might have put it, all true sentences are alike, but every false sentence is false in its own unique way.) Which way a sentence is false can affect the truth value of compounds containing that sentence. In particular, if \(A\) and \(B\) are false, then the truth values of \textit{Not A} and \textit{If A then B} will depend on the ways \(A\) and \(B\) take their truth values. If \(V\)(\(A\)) = 0 and \(V\)(\(B\)) = 0.3, then \textit{Not A} and \textit{If A then B} will be true, but if \(V\)(\(A\)) becomes 0.6, and remember this is just another way of being false, both \textit{Not A} and \textit{If A then B} will be false.

The new theory we get, one I'll call \(M_D\), is similar to \(M\) in some respects. For example, it agrees about what the axioms should be for a logic for natural language. But it has several philosophical differences. In particular, it has none of the three characteristics of \(M\) we noted above. 

It cannot tell as plausible story as \(M\) does about the Sorites. If any sentence with truth value below 1 is false, then many of the premises in a Sorites argument are \textit{false}. This is terrible -- it was bad enough to be told that one of the premises were false, but now we find many thousands of them are false. I doubt that being told they are false in a distinctive way will improve our estimation of the theory. Similarly, it is hard to see just how the new theory has anything interesting to say about the concept of a borderline case. 

On the other hand, according to \(M_D\), contradictions are always false. To be sure, a contradiction might be false in some obscure new way, but it is still false. Recall Williamson's objection that an explicit contradiction should be true to degree 0 and nothing more. This objection only works if being true to degree 0.5 is meant to be semantically significant. If being `true to degree 0.5' is just another way of being false, then there is presumably nothing wrong with contradictions are true to degree 0.5. This is not to say Williamson's objection is no good, since he intended it as an objection to \(M\), but just to say that re-interpreting the semantic significance of the numbers in \(M\) makes a philosophical difference.

Despite \(M_D\)'s preferable treatment of contradictions, I think \(M\) is overall a better theory because it has a much better account of borderline cases. But for now I want to stress a simpler point: \(M\) and \(M_D\) are \textit{different} theories of vagueness, and that we grasp the difference between these theories. One crucial difference between the two theories is that in \(M\), but not \(M_D\), \(S_1\)is truer than \(S_2\) if \(V\)(\(S_1\)) is greater than \(V\)(\(S_2\)). In \(M_D\), if \(S_1\)is truer than \(S_2\), \(V\)(\(S_1\)) must be one and \(V\)(\(S_2\)) less than one. And that is the \textit{only }difference between the two theories. So if we understand this difference, we must grasp this concept \textit{truer than}. Indeed, it is in virtue of grasping this concept that we understand why saying each of the Sorites conditionals is almost true is a \textit{prima facie} plausible response to the Sorites, and why having a theory that implies contradictions are truer than many other sentences is a rather embarrassing thing. 

I have implicitly defined \textit{truer} by noting its theoretical role. As David \citet{Lewis1972a} showed, terms can be implicitly defined by their theoretical role. There is one unfortunate twist here in that \textit{truer} is defined by its role in a \textit{false} theory, but that does not block the implicit definition story. We know what \textit{phlogiston} and \textit{ether} mean because of their role in some false theories. The meaning of \textit{truer} can be extracted in the same way from the false theory \(M\). 

\section{Further Reflections on \textit{Truer}}
As noted, I won't give a reductive analysis of \textit{truer}. The hopes for doing that are no better than the hopes of giving a reductive analysis of \textit{true}. But I will show that we pre-theoretically understand the concept.

My primary argument for this has already been given. Intuitively we do understand the difference between \(M\) and its \(M_D\), and this is only explicable by our understanding \textit{truer}. Hence we understand \textit{truer}.

Second, it's noteworthy that \textit{truer} is morphologically complex. If we understand \textit{true}, and understand the modifier -\textit{er}, then we know enough in principle to know how they combine. Not every predicate can be turned into a comparative. But most can, and our default assumption should be that \textit{true} is like the majority.

I have heard two arguments against that assumption. First, it could be argued that most comparatives in English generate linear orderings, but \textit{truer} generates a non-linear ordering. I reject the premise of this argument. \textit{Cuter}, \textit{Smarter}, \textit{Smellier}, and \textit{Tougher} all generate non-linear orderings over their respective domains, and they seem fairly indicative of large classes. Second, it could be argued that it's crucial to understanding comparatives that we understand the interaction of the underlying adjectives with comparison classes. Robin Jeshion and Mike Nelson made this objection in their comments on my paper at BSPC 2003. Again, the premise is not obviously true. We can talk about some objects being \textit{straighter} or \textit{rounder} despite the fact that it's hard to understand \textit{round for an office building} or \textit{straight for a line drive}. (Jonathan Bennett made this point in discussion at BSPC.) \textit{Straight} and \textit{round} either don't have or don't need comparison classes, but they form comparatives. So \textit{true}, which also does not take comparison classes, could also form a comparative.

Finally, if understanding the inferential role of a logical operator helps know its meaning, then it is notable that \textit{truer} has a very clear inferential role. It is the same as a strict material implication \(\square (q \supset p)\) defined using a necessity operator whose logic is KT. Since many operators have just this logic, this doesn't individuate \textit{truer}, but it helps with inferential role semantics aficionados.

I claim that the concept \textit{truer}, and the associated concept \textit{as true as}, are the only theoretical tools we need to provide a complete theory of vagueness. It is simplest to state the important features of my theory by contrasting it with \(M\). I keep the following good features of \(M\).

\begin{description}
\item[G1] There are \textit{intermediate} sentences, i.e. sentences that are truer than some sentences and less true than others. For definiteness, I will say \(S\) is intermediate iff \(S\) is truer than 0=1 and less true than 0=0.
\item[G2] \(a\) is a borderline \(F\) iff \textit{a is F} is intermediate, and \(a\) is determinately \(F\) iff \(a\) is \(F\) and \(a\) is not a borderline \(F\).
\end{description}

\noindent I won't repeat the arguments here, but I take G1 to be a large advantage of theories like \(M\) over epistemicist theories. (See \citet{Burgess2001}, \citet{Sider2001} and \citet{Weatherson2003-WEAEPA} for more detailed arguments to this effect.) And as noted G2 is a much simpler analysis of determinacy and borderline than supervaluationists have been able to offer.

I drop the following bad features of \(M\).

\begin{description}
\item[B1 \textit{Some contradictions are intermediate sentences}.]  \hspace*{\fill} \\
On my theory all contradictions are determinately false, and determinately determinately false, and so on. The argument for this has been given above.
\item[B2 \textit{Some classical tautologies are intermediate sentences}.]  \hspace*{\fill} \\
On my theory all classical tautologies are determinately true, and determinately determinately true, and so on. We will note three arguments for this being an improvement in the next section.
\item[B3 \textit{Some classical inference rules are inadmissible}.] \hspace*{\fill} \\
On my theory all classical inference rules are admissible. As \citet{Williamson1994-WILV} showed, the most prominent version of supervaluationism is like \(M\) in ruling some classical rules to be inadmissible, and this is clearly a cost of those theories.
\item[B4 \textit{Sentences of the form }S is intermediate\textit{ are never intermediate}] \hspace*{\fill} \\
I will argue below this is a consequence of \(M\), and it means it is impossible to provide a plausible theory of higher-order vagueness within \(M\). In my theory we can say that there is higher-order vagueness by treating \textit{truer} as an iterable operator, so we can say that \textit{S is intermediate} is intermediate. If \(S\) is \textit{a is F}, that's equivalent to saying that \(a\) is a borderline case of a borderline case of an \(F\). Essentially we get out theory of higher-order vagueness by simply iterating our theory of first-order vagueness, which is what Williamson does in his justly celebrated treatment of higher-order vagueness. Note it's not just \(M\) that has troubles with higher-order vagueness. See \citet{Williamson1994-WILV} and \citet{Weatherson2003-Keefe} for the difficulties supervaluationists have with higher-order vagueness. The treatment of higher-order vagueness here is a substantial advantage of my theory over supervaluationism.
\item[B5 \textit{Truer is a linear relation}.] \hspace*{\fill} \\
On my theory it need not be the case that \(S_1\)is truer than \(S_2\), or \(S_2\) is truer than \(S_1\), or they are as true as each other. In the last section I will argue that this is a substantial advantage of my theory. I claim that \textit{truer} generates a Boolean lattice on possible sentences of the language. (For a familiar example of a Boolean lattice, think of the subsets of \(\mathbb{R}\) ordered by the subset relation.)
\end{description}

\noindent I also provide a very different, and much more general, treatment of the Sorites than is available within \(M\). The biggest technical difference between my theory and \(M\) concerns the relationship between the semantics and the logic. In \(M\) the logic falls out from the truth-tables. Since I do not have the concept of an intermediate truth value in my theory, I could not provide anything like a truth-table. Instead I posit several constraints on the interaction of \textit{truer} with familiar connectives, posit an analysis of validity in terms of \textit{truer}, and note that those two posits imply that all and only classically admissible inference rules are admissible.

\section{Constraints on Truer and Classical Logic}
The following ten constraints on \textit{truer} seem intuitively compelling. I've listed here both the philosophically important informal claim, and the formal interpretation of that claim. (I use \(A \geqslant _T B\) as shorthand for \(A\) \textit{is at least as }\textit{true as B}. Note all the quantifiers over sentences here are \textit{possibilist} quantifiers, we quantify over all possible sentences in the language.)

\begin{description}
\item[(A1)] \(\geqslant _T\) is a weak ordering (i.e. reflexive and transitive)  \hspace*{\fill} \\
If \(A \geqslant _T B\) and \(B \geqslant _T C\) then \(A \geqslant _T C\)  \hspace*{\fill} \\
\(A \geqslant _T A\)
\item [(A2)] \(\wedge\) is a greatest lower bound with respect to \(\geqslant _T\)  \hspace*{\fill} \\
\(A \wedge B \geqslant _T C\) iff \(A \geqslant _T C\) and \(B \geqslant _T C\)  \hspace*{\fill} \\
\(C \geqslant _T\)\textit{ A}\(\wedge B\) iff for all \(S\) such that \(A \geqslant _T S\) and \(B \geqslant _T\)\textit{S }it is also the case that \(C \geqslant _T S\)
\item [(A3)]\(\vee\) is a least upper bound with respect to \(\geqslant _T\)  \hspace*{\fill} \\
\(A \vee B \geqslant _T C\) iff for all \(S\) such that \(S \geqslant _T A\)~and \(S \geqslant _T B\), it is also the case that \(S \geqslant _T C\)  \\
\(C \geqslant _T\)\textit{ A}\(\vee B\) iff \(C \geqslant _T A\) and \(B \geqslant _T C\)
\item[(A4)] \(\neg\) is ordering inverting with respect to \(\geqslant _T\)  \hspace*{\fill} \\
\(A \geqslant _T B\) iff \(\neg B \geqslant _T \neg A\)
\item [(A5)] Double negation is redundant  \hspace*{\fill} \\
\(\neg \neg A =_T A\)
\item[(A6)] There is an absolutely false sentence \(S_F\) and an absolutely true sentence \(S_T\)  \hspace*{\fill} \\
There are sentences \(S_F\)and \(S_T\)such that \(S_F =_T \neg S_T\) and \(\neg S_F =_T S_T\)~ and for all \(S\): \(S_T \geqslant _T S \geqslant _T S_F\)
\item[(A7)] Contradictions are absolutely false  \hspace*{\fill} \\
\(A \wedge \neg A =_T S_F\)
\item[(A8)] \(\forall\) is a greatest lower bound with respect to \(\geqslant _T\)  \hspace*{\fill} \\
\(A \geqslant _T \forall x\)(\(\phi x\))~iff for all \(S\) such that for all \(o\), if \(n\) is a name of \(o\) then \(\phi n \geqslant _T S\), it is the case that \(A \geqslant _T S\)  \hspace*{\fill} \\
\(\forall x\)(\(\phi x\))~\(\geqslant _T A\) iff for all \(o\), if \(n\) is a name of \(o\) then \(\phi n \geqslant _T A\)
\item[(A9)] \(\exists\) is a least upper bound with respect to \(\geqslant _T\)  \hspace*{\fill} \\
\(A \geqslant _T \exists x\)(\(\phi x\))~iff for all \(o\), if \(n\) is a name of \(o\) then \(A \geqslant _T \phi\)\textit{n}\(\exists x\)(\(\phi x\))~\(\geqslant _T A\) iff for all \(S\) such that for all \(o\), if \(n\) is a name of \(o\) then \(S \geqslant _T \phi n\), \(S \geqslant _T A\)
\item [(A10)] A material implication with respect to \(\geqslant _T\) can be defined.  \hspace*{\fill} \\
There is an operative \(\rightarrow\) such that 
\begin{enumerate}
\item \(B \rightarrow A \geqslant _T S_T\)iff \(A \geqslant _T B\)
\item (\(A \wedge B\))\( \rightarrow C =_T A  \rightarrow\)(\(B \rightarrow C\))
\end{enumerate}
\end{description}

\noindent Apart from (A10) these are fairly straightforward. We can't argue for (A10) by saying English \textit{if{\dots}then} is a material implication, because that leads directly to the paradoxes of material implication. Assuming that \(\neg A \vee B\) is a material implication is equivalent to assuming (inter alia) that \(A \vee \neg A\) is perfectly true. I believe this, but since it is denied by many I want that to be a conclusion, not a premise. So the argument for (A10) must be a little indirect. In particular, we will appeal to the behaviour of quantifiers. We can formally represent \textit{All Fs are Gs} in two ways: using restricted or unrestricted quantifiers. In the first case the formal representation will look like:

\begin{quote}
\(\forall x\)(\textit{Fx} ? \textit{Gx})
\end{quote}

\noindent with some connective in place of `?'. But it seems clear that whatever connective goes in there must be a material implication. In the second case, the formal representation will look like:

\begin{quote}
[\(\forall x\): \textit{Fx}] \textit{Gx}
\end{quote}

\noindent In that case, we can define a connective \(\nabla\) that satisfies the definition of a material implication:

\begin{quote}
\(A \nabla B\)~=\textsubscript{df} [\(\forall x\): \(A \wedge x\)=\(x\)] (\(B \wedge x\)=\(x\))
\end{quote}

\noindent This is equivalent to the odd (but intelligible) sentence \textit{Everything such that A is such that B}. Again, considerations about what should be logical truths involving quantifiers suggests that \(\nabla\) must be a material implication. So either way there should be a material implication present in the language, as (A10) says.

Given (A1) to (A10) it follows that this material implication is equivalent to \(\neg A \vee B\), and hence \(A \vee \neg A\) is a logical truth. This is a surprising \textit{conclusion}, since intuitively vagueness poses problems for excluded middle, but I think it is more plausible that vague instances of excluded middle are problematic for \textit{pragmatic} reasons than that any of (A1) to (A10) are false. 

What is interesting about these ten constraints is that they suffice for classical logic, with just one more supposition. I assume that an argument is \textit{valid} iff it is impossible for the premises taken collectively to be truer than the conclusion, i.e. iff it is impossible for the conjunction of the premises to be truer than the conclusion. Given that, we get:

\begin{quote}
\(\forall A_1\), {\dots},\(A_n\),\(B\): \(A_1\), {\dots}, \(A_n \vdash\)\textsubscript{T}~\(B\) iff, according to classical logic, \(A_1\), {\dots},~\(A_n\) \(\vdash\) \(B\)
\end{quote}

\noindent (I use   \(\Gamma\) \(\vdash\)\textsubscript{T} \(A\) to mean that in all models for \(\geqslant _T\) that satisfy the constraints, here (A1) to (A10), the conclusion is at least as true as the greatest lower bound of the premises.) I won't prove this result, but the idea is that (A1) to (A10) imply that \(\geqslant _T\) defines a Boolean lattice over equivalence classes of sentences with respect to \(=_T\). And all Boolean lattices are models for classical logic, from which our result follows. Indeed, Boolean lattices are models for classical logic in the strong sense that classical inference rules, such as conditional proof and \textit{reductio}, are admissible in logics defined on them, so we also get the admissibility of classical inference rules in this theory. (Note that this result only holds in the right-to-left direction for languages that contain the \(\geqslant _T\) operator. Once this operator is added, some arguments that are not classically valid, such as \(B \geqslant _T A\), \(A \vdash\)\textsubscript{T}~\(B\), will valid. But the addition of this operator is conservative: if we look at the \(\geqslant _T\){}-free fragment of such languages, the above result still holds in both directions.)

There are three reasons for wanting to keep classical logic in a theory of vagueness. First, as Williamson has stressed, classical logic is at the heart of many successful research programs. Second, non-classical theories of vagueness tend to abandon too much of classical logic. For instance, \(M\) abandons the very plausible schema (\(A \wedge A \rightarrow B\))\(\rightarrow B\). The third reason is the one given here - these ten independently plausible constraints on \textit{truer} entail that the logic for a language containing \textit{truer} should be classical. These three arguments add up to a powerful case that non-classical theories like \(M\) are mistaken, and we should prefer a theory that preserved classical logic.

\section{Semantics and Proof Theory}
In this section I will describe a semantics and proof theory for a language containing \textit{truer} as an iterable operator. This is important for the theory of higher-order vagueness. I say that \(a\) is a borderline borderline \(F\) just in case the sentence \textit{a is a borderline F} is intermediate, where `borderline' is analysed as in section 2. It might not be obvious that it is consistent with (A1) to (A10) that any sentence \textit{a is a borderline F} could be consistent. One virtue of the model theory outlined here is that it shows this is consistent.

For comparison, note that \(M\) as it stands has no way of dealing with higher\nobreakdash-order vagueness, i.e. with borderline cases of borderline cases of \(F\){}-ness. If every sentence \textit{a is a borderline F }either does or does not receive an integer truth value, then this intuitive possibility is ruled out. We cannot solve the problem simply by iterating \(M\). (This is a point stressed by \cite[Ch. 4]{Williamson1994-WILV}.) We cannot say that it is true to degree 0.5 than (2) is true to degree 1, and true to degree 0.5 that it is true to degree 0.8. For then it is only true to degree 0.5 that (2) has some truth value or other. And the use of truth-tables to generate a logic presupposes that every sentence has some truth values or other. If this is not determinately true, \(M\) is not a complete theory. So the model theory will show that our theory is substantially better than \(M\) in this respect.

Consider the following (minor) variant on KT. Vary the syntax so \(\square A\) is only well-formed if \(A\) is of the form \(B \rightarrow C\). Call the resulting logic KT\textsubscript{R}, with the R indicating the syntactic restriction. The restriction makes very little difference. Since \(A\) is equivalent to (\(A \rightarrow A\))~\(\rightarrow A\), even if \(\square A\) is not well-formed in KT\textsubscript{R}, the KT-equivalent sentence \(\square\)((\(A \rightarrow A\))~\(\rightarrow A\)) will be well-formed. The Kripke models for KT\textsubscript{R} are quite natural. \(\square\)(\(B \rightarrow C\)) is true at a point iff all accessible points at which \(B\) is true are points at which \(C\) is true. (There is no restriction on the accessibility relation other than reflexivity.)

Since KT\textsubscript{R} is so similar to KT, we can derive most of its formal properties by looking at the derivations of similar properties for KT. (The next few paragraphs owe a lot to \cite[Chs.1-3]{Goldblatt1992}.) Let's start with an axiomatic proof theory. The axioms for KT\textsubscript{R} are:

\begin{itemize}
\item All classical tautologies
\item All well-formed instances of K: \(\square\)(\(A \rightarrow B\))~\(\rightarrow\)~(\(\square A \rightarrow \square B\))
\item All well-formed instances of T: \(\square A \rightarrow A\)
\end{itemize}

\noindent The rules for KT\textsubscript{R} are

\begin{description}
\item[Modus Ponens] If \(A \rightarrow B\) is a theorem and \(A\) is a theorem, then \(B\) is a theorem
\item[Restricted Necessitation] If \(A\) is a theorem and \(\square A\) is well-formed, then \(\square A\) is a theorem.
\end{description}

\noindent Given these, we can now define a maximal consistent set for KT\textsubscript{R}. It is a set \(S\) of sentences with the following three properties:

\begin{itemize}
\item All theorems of KT\textsubscript{R} are in \(S\).
\item For all \(A\), either \(A\) is in \textit{S }or \(\neg A\) is in \(S\).
\item \(S\) is closed under modus ponens.
\end{itemize}

\noindent The existence of Kripke models for KT\textsubscript{R} show that some maximal consistent sets exist: the set of truths at any point will be a maximal consistent set. The canonical model for KT\textsubscript{R} is \(\langle W, R, V \rangle\) where

\begin{itemize}
\item \textit{W} is the set of maximal consistent sets for KT\textsubscript{R}
\item \textit{R} is a subset of \textit{W} \(\times\) \textit{W} such that \textit{w}\textsubscript{1}\textit{Rw}\textsubscript{2} iff for all \(A\) such that \(\square A \in\) \textit{w}\textsubscript{1}, \(A \in\)~\textit{w}\textsubscript{2}
\item \(V\) is the valuation such that \(V\)(\(A\))~= \{\textit{w}: \(A \in\)~\textit{w}\}
\end{itemize}

\noindent Since all instances of T are theorems, it can be easily shown that \textit{R} is reflexive, and hence that this is a frame for KT\textsubscript{R} and hence that KT\textsubscript{R} is canonically complete.

We can translate all sentences of KT\textsubscript{R} into a language that contains \(\geqslant _T\) but not \(\square\). Just replace \(\square\)(\(B \rightarrow A\)) with \(A \geqslant _T B\) wherever \(\square\) occurs including inside sentences. (We appeal here and here alone to the restriction in KT\textsubscript{R}.) Translating the axioms for KT\textsubscript{R}, we get the following axioms for the logic of \(\geqslant _T\).

\begin{itemize}
\item All classical tautologies
\item All instances of: (\(B\)~~\(\geqslant _T A\))~\(\rightarrow\)~((\(A \geqslant _T\)~(\(A \rightarrow A\)))~\(\rightarrow\) (\(B \geqslant _T\)~(\(B \rightarrow B\))))
\item All instances of: (\(B \geqslant _T A\))~\(\rightarrow\)~(\(A \rightarrow B\))
\end{itemize}

\noindent The rules are

\begin{description}
\item [Modus ponens] If \(A \rightarrow B\) is a theorem and \(A\) is a theorem, then \(B\) is a theorem.
\item [Determination] If \(A \rightarrow B\) is a theorem, then \(B \geqslant _T A\) is a theorem.
\end{description}

\noindent We can simplify somewhat by replacing the second axiom schema with

\begin{itemize}
\item All instances of: \(A \geqslant _T B \rightarrow\)~(\(B \geqslant _T C \rightarrow A \geqslant _T C\))
\end{itemize}

\noindent A Kripke model for this logic is just a Kripke model for KT, except we say \(B \geqslant _T A\) is true at a point iff \(B\) is true at all accessible points at which \(A\) is true. This leads to a semantic definition of validity. An argument is valid iff it preserves truth at any point in all such models. 

Maximal consistent sets with respect to \(\geqslant _T\) and a canonical model for \(\geqslant _T\) can be easily constructed by parallel with the maximal consistent sets and canonical models for KT\textsubscript{R}. These constructions show that if \(A\) is a theorem of the logic for \(\geqslant _T\), then it is true at all points in all models. More generally, they can be used to show that this logic is canonically complete, though the details of the proof are omitted. The maximal consistent sets for \(\geqslant _T\), i.e. the points in the canonical model, just are the results of applying the translation rule \(\square\)(\(B \rightarrow A\))~\(\Rightarrow A \geqslant _T B\) to the (sentences in the) maximal consistent sets for KT\textsubscript{R}.

That's important because the points in the canonical model for \(\geqslant _T\) are useful for understanding the relationship between \textit{truer} and \textit{true}, and for understanding what languages are. The set of true sentences in English is one of the points in the canonical model for \(\geqslant _T\). For semantic purposes, languages just are points in this canonical model. It is indeterminate just which such point English is, but it is one of them. For many purposes it is useful to think of the theory based on \textit{truer} as a variant on \(M\). But considering the canonical model for \(\geqslant _T\) highlights the similarities with supervaluationism rather than the similarities with \(M\), for the points in the canonical model look a lot like precisifications. It is, however, worth noting the many differences between my theory and supervaluationism. I identify languages with a single point rather than with a set of points, which leads to the smoother treatment of higher-order vagueness on my account. Also, I don't start with a set of acceptable points/precisifications. The canonical model contains all the points that are formally consistent, and I identify particular languages, like English, by vaguely saying that the point that represents English is (roughly) there. (Imagine my vaguely pointing at some part of the model when saying this.) The most important difference is that I take the points, with the truer than relation already defined, to be primitive, and the accessibility/acceptability relation to be defined in terms of them. This reflects the fact that I take the \textit{truer} relation to be primitive, and determinacy to be defined in terms of it, whereas typically supervaluationists do things the other way around. None of these differences are huge, but they all favour my theory over supervaluationism. 

To return to the point about higher order vagueness, note that all of the following sentences are consistent in KT, and hence their `equivalents' using {\textgreater}\textsubscript{T} are also consistent.

\numbex{0}{
\item \(\neg \square p \wedge \neg \square \neg p\) \hspace*{\fill} \\
0=0 {\textgreater}\textsubscript{T}~\(p\)~{\textgreater}\textsubscript{T}~0=1
\smallskip
\item \(\neg \square\)(\(\neg \square p \wedge \neg \square \neg p\)) \(\wedge \neg \square \neg\)(\(\neg \square p \wedge \neg \square \neg p\)) \hspace*{\fill} \\
0=0 {\textgreater}\textsubscript{T}~(0=0 {\textgreater}\textsubscript{T}~\(p\)~{\textgreater}\textsubscript{T}~0=1) {\textgreater}\textsubscript{T}~0=1
\smallskip
\item \(\neg \square\)(\(\neg \square\)(\(\neg \square p \wedge \neg \square \neg p\))\(\wedge \neg \square \neg\)(\(\neg \square p \wedge \neg \square \neg p\)))  \hspace*{\fill} \\
\(\wedge \neg \square \neg\)(\(\neg \square\)(\(\neg \square p \wedge \neg \square \neg p\))\(\wedge \neg \square \neg\)(\(\neg \square p \wedge \neg \square \neg p\))) \hspace*{\fill} \\
0=0 {\textgreater}\textsubscript{T}~(0=0 {\textgreater}\textsubscript{T}~(0=0 {\textgreater}\textsubscript{T}~\(p\)~{\textgreater}\textsubscript{T}~0=1) {\textgreater}\textsubscript{T}~0=1) {\textgreater}\textsubscript{T}~0=1
}

\noindent And obviously this pattern can be extended indefinitely. In general, any claim of the form that \(a\) is an \(n\){}-th order borderline case of an \(F\) is consistent in this theory, as can be seen by comparison with KT.

To close this section, I will note that we can also provide a fairly straightforward natural deduction system for the logic of \(\geqslant _T\). There are two philosophical benefits to doing this. First, it proves my earlier claim that I can keep all inference rules of classical logic. Second, it helps justify (A1) to (A10). Most rules correspond directly to one of the constraints. For that reason I've set all the rules, even though you've probably seen most of them before.

\begin{description}

\item [(\(\wedge\) In)]  \(\Gamma\) \(\vdash\) \(A\), \(\Delta\) \(\vdash\) \(B \Rightarrow \Gamma \cup\Delta \vdash A \wedge B\)

\item [(\(\wedge\) Out-left)]  \(\Gamma\)  \(\vdash\)  \(A \wedge B \Rightarrow\)  \(\Gamma\) \(\vdash\) \(A\)

\item [(\(\wedge\) Out-right)]  \(\Gamma\)  \(\vdash\)  \(A \wedge B \Rightarrow\)  \(\Gamma\) \(\vdash\) \(B\)

\item [(\(\vee\) In-left)]  \(\Gamma\) \(\vdash\) \(B \Rightarrow\)~ \(\Gamma\) \(\vdash\) \(A \vee B\)

\item [(\(\vee\) In-right)]  \(\Gamma\) \(\vdash\) \(A \Rightarrow\)~ \(\Gamma\) \(\vdash\) \(A \vee B\)

\item [(\(\vee\) Out)]  \(\Gamma \cup\)\{\(A\)\} \(\vdash\) \(C\), \(\Delta \cup\)\{\(B\)\} \(\vdash\) \(C\), \(\Lambda\)  \(\vdash\) ~\(A \vee B \Rightarrow\) \(\Gamma \cup \Delta \cup \Lambda \vdash C\)

\item [(\(\rightarrow\) In)]  \(\Gamma \cup\)\{\(A\)\} \(\vdash\) \(B \Rightarrow\)~ \(\Gamma\) \(\vdash\) \(A \rightarrow B\)

\item [(\(\rightarrow\) Out)]  \(\Gamma\) \(\vdash\) \(A \rightarrow B\), \(\Delta\) \(\vdash A \Rightarrow \Gamma \cup \Delta \vdash B\)

\item [(\(\neg\) In)]  \(\Gamma \cup\)\{\(A\)\} \(\vdash\) \(B \wedge \neg B \Rightarrow\)~ \(\Gamma\) \(\vdash\) \(\neg A\)

\item [(\(\neg\) Out)]  \(\Gamma\) \(\vdash \neg \neg A \Rightarrow\) \(\Gamma\) \(\vdash\) \(A\)

\item [(\(\geqslant _T\) In)]  \(\Gamma\) \(\vdash\) \(A \Rightarrow\) \{\(B \geqslant _T C\): \(B \in\)~ \(\Gamma\)\}  \(\vdash\) ~\(A \geqslant _T C\)

\item [(\(\geqslant _T\) Convert)]  \(\Gamma\)  \(\vdash\) ~\(A \geqslant _T B \Rightarrow\)~ \(\Gamma\) \(\vdash\) (\(B \rightarrow A\))\(\geqslant _T C\)

\item [(\(\geqslant _T\) Out)]  \(\Gamma\) \(\vdash\) \(A \geqslant _T B \Rightarrow\)~ \(\Gamma\)  \(\vdash\) ~\(B \rightarrow A\)
\end{description}

\noindent (Thanks to Gabriel Uzquiano for several probing questions that led to this section being written.)

\section{Sexy Sorites }
A good theory of vagueness should tell us two things about the Sorites. The easy part is to say what is wrong with Sorites arguments: not all premises are perfectly true. The hard part is to say why the premises looked plausible to start with. The \(M\) theorist has the beginnings of a story, though not the end of a story. The beginning is that all the premises in a typical Sorites argument are nearly true, and they look plausible because we confuse near truth for truth. Can I say the same thing, since my theory is like \(M\)? No, for two reasons. First, since my theory explicitly gets rid of numerical representations of intermediate truth values, I don't have any way to analyse \textit{almost true}. Second, since I say that one of the Sorites premises is false, I'd be committed to the odd view that some false sentence is almost perfectly true. Thanks to Cian Dorr for pointing out this consequence.

The story the \(M\) theorist tells does not generalise. The problem is that not all Sorites arguments involve conditionals. A typical Sorites situation involves a chain from a definite \(F\) to a definite not-\(F\). Let \(^\prime\) denote the successor relation in this sequence, so if \(F\) is \textit{is tall} and \(a\) is 178cm tall, then \(a ^\prime\) will be 177.99cm tall, assuming the sequence progresses 0.1mm at a time. According to \(M\), every premise like (SI) is almost true.

\begin{description}
\item[(SI)] If \(a\) is tall, then \(a ^\prime\) is tall.
\end{description}

\noindent But we could have built a Sorites argument with premises like (SA).

\begin{description}
\item[(SA)] It is not the case that \(a\) is tall and \(a ^\prime\) is not tall.
\end{description}

\noindent And premises of this form are not, in general, almost true. Indeed, some will have a truth value not much about 0.5. So \(M\) has no explanation for why premises like (SA) look persuasive. This is quite bad, because (SA) is \textit{more} plausible than (SI) as I'll now show. Consider the following thought experiment. You are trying to get a group of (typically non-responsive) undergraduates to appreciate the force of the Sorites paradox. If they don't feel the force of (SI), how do you persuade them? My first instinct is to appeal to something like (SA). If that doesn't work, I appeal to theoretical considerations about how our use of \textit{tall} couldn't possibly pick a boundary between \(a\) and \(a ^\prime\). I think I find (SI) plausible \textit{because} I find (SA) plausible, and I would try to get the students to feel likewise. There's an asymmetry here. I wouldn't defend (SA) by appealing to (SI), and I don't find (SA) plausible because it follows from (SI). (This is not to endorse universally quantified versions of either (SA) or (SI). They are like Axiom V - claims that remain intuitively plausible even when we know they are false.)

Sadly, many theories have little to say about why (SA) seems true. The official epistemicist story is that speakers only accept sentences that are determinately, i.e. knowably, true. But some instances of (SA) are actually \textit{false}, and many many more are not knowably true. The supervaluationist story about (SA) is no better.

Here's a surprising fact about the Sorites that puts an unexpected constraint on explanations of why (SA) is plausible. In the history of debates about it, I don't think anyone has put forward a Sorites argument where the major premises are like (SO).

\begin{description}
\item [(SO)] Either \(a\) is not tall, or \(a ^\prime\) is tall.
\end{description}

\noindent (This point is also noticed in \citet{SiderBraun}.) There's a good reason for this: (SO) is \textit{not} intuitively true, unless perhaps one sees it as a roundabout way of saying (SA). In this respect it conflicts quite sharply with (SA), which \textit{is} intuitively true. But hardly any theory of vagueness (certainly not \(M\) or supervaluationism or epistemicism) provide grounds for distinguishing (SA) from (SO), since most theories of vagueness endorse DeMorgan's laws. Further, none of the many and varied recent solutions to the Sorites that do not rely on varying the underlying logic (e.g. \citet{Fara2000, Sorensen2001, Eklund2002}) seem to do any better at distinguishing (SA) from (SO). As far as I can tell none of these theories \textit{could}, given their current conceptual resources, tell a story about why (SA) is intuitively plausible that does not falsely predict (SO) is intuitively plausible. That is, none of these theories could solve the Sorites paradox with their current resources.

There is, however, a simple theory that does predict that (SA) will look plausible while (SO) will not. Kit \citet{Fine1975a} noted that if we assume that speakers systematically confuse \(p\) for \textit{Determinately p}, even when \(p\) occurs as a constituent of larger sentences rather than as a standalone sentence, then we can explain why speakers may accept vague instances of the law of non-contradiction, but not vague instances of the law of excluded middle. (That speakers do have these differing reactions to the two laws has been noted in a few places, most prominently \citet{Burgess1987} and \citet{Tappenden1993}.) It's actually rather remarkable how many true predictions one can make using Fine's hypothesis. It correctly predicts that (5) should sound acceptable. 

\numbex{4}{
\item It is not the case that I am tall, but nor is it the case that I am not tall.
}

\noindent Now (5) is a contradiction, so both the fact that it sounds acceptable if I am a borderline case of vagueness, and the fact that some theory predicts this, are quite remarkable. This is about as good as it gets in terms of evidence for a philosophical claim.

(We might wonder just why Fine's hypothesis is true. One idea is that there really isn't any difference in truth value between \(p\) and \textit{Determinately p}. This leads to the absurd position that some contradictions, like (5), are literally true. I prefer the following two-part explanation. The first part is that when one utters a simple subject-predicate sentence, one implicates that the subject \textit{determinately} satisfies the predicate. This is a much stronger implicature than conversational implicature, since it is not cancellable. And it does not seem to be a conventional implicature. Rather, it falls into the category of nonconventional nonconversational implicatures Grice suggests exists on pg. 41 of his \citeyear{Grice1989}. The second part is that some implicatures, including determinacy implicatures, are computed locally and the results of the computations passed up to whatever system computes the intuitive content of the whole sentence. This implies that constituents of sentences can have implicatures. This theme has been studied quite a bit recently; see \citet{Levinson2000} for a survey of the linguistic data and \citet{Sedivy1999} for some empirical evidence supporting up this claim. Just which, if any, implicatures are computed locally is a major research question, but there is \textit{some }evidence that Fine's hypothesis is the consequence of a relatively deep fact about linguistic processing. This isn't essential to the current project - really all that matters is that Fine's hypothesis is true - but it does suggest some interesting further lines of research and connections to ongoing research projects.)

If Fine's hypothesis is true, then we have a simple explanation for the attractiveness of (SA). Speakers regularly confuse (SA) for (6), which is true, while they confuse (SO) for (7), which is false.

\numbex{5}{
\item It is not the case that \(a\) is determinately tall and \(a ^\prime\) is determinately not tall.
\item Either \(a\) is determinately not tall, or \(a ^\prime\) is determinately tall.
}

\noindent This explanation cannot \textit{directly} explain why speakers find (SI) attractive. My explanation for this, however, has already been given. The intuitive force behind (SI) comes from the fact that it follows, or at least appears to follow, from (SA), which looks practically undeniable.

So Fine's hypothesis gives us an explanation of what's going on in Sorites arguments that is available in principle to a wide variety of theorists. Fine proposed it in part to defend a supervaluationist theory, and \citet{Keefe2000} adopts it for a similar purpose. Patrick \citet{Greenough2003} has recently adopted a similar looking proposal to provide an epistemicist explanation of similar data. (Nothing in the explanation of the attractiveness of Sorites premises turns on any \textit{analysis} of determinacy, so the story can be told by epistemicists and supervaluationists alike.) And the story can be added to the theory of \textit{truer} sketched here. It might be regretted that we don't have a \textit{distinctive} story about the Sorites in terms of \textit{truer}. But the hypothesis that some sentences are truer than others is basically a \textit{semantic} hypothesis, and if the reason Sorites premises look attractive is anything like the reason (5) looks \textit{prima facie} attractive, then that attractiveness should receive a \textit{pragmatic} explanation.  What is really important is that there be some story about the Sorites we can tell.

\section{Linearity Intuitions}
The assumption that \textit{truer} is a non-linear relation is the basis for most of the distinctive features of my theory, so it should be defended. There are two reasons to believe it.

One is that we can't simultaneously accept all of the following five principles. 

\begin{itemize}
\item \textit{Truer} is a linear relation. 
\item (A2), that conjunction is a greatest lower bound. 
\item (A4), that negation is order inverting. 
\item (A7), that contradictions are determinately false. 
\item There are indeterminate sentences. 
\end{itemize}

\noindent I think by far the least plausible of these is the first, so it must go.

Linearity (or at least determinate linearity) also makes it difficult to tell a plausible story about higher order vagueness. Linearity is the claim that for any two sentences \(A\) and \(B\), the following disjunction holds. Either \(A\)~{\textgreater}\textsubscript{T}~\(B\), or \(B\)~{\textgreater}\textsubscript{T}~\(A\), or \(A =_T B\). If truer is determinately linear, that disjunction is determinately true. And if \textit{truer} is linear, and if that disjunction is determinately true, then one of its disjuncts must be determinately true, for linearity rules out the possibility of a determinately true disjunction with no determinately true disjunct. Now take a special case of that disjunction, where \(B\) is 0=0. In that case we can rule out \(A\)~{\textgreater}\textsubscript{T}~\(B\). So the only options are \(B\)~{\textgreater}\textsubscript{T}~\(A\) or \(A =_T B\). We have concluded that given linearity, one of these disjuncts must be determinately true. That is, \(A\) is either determinately intermediate or determinately determinate. But intuitively neither of these need be true, for \(A\) might be in the `penumbra' between the determinately intermediate and the determinately determinate. This argument is only a problem if we assume determinate linearity, but it's hard to see the theoretical motivation for believing in linearity but not determinate linearity.

Still, it is very easy to believe in linearity. Even for comparatives that are clearly non-linear, like \textit{more intelligent than}, there is a strong temptation to treat them as linear. (Numerical measurements of intelligence are obviously inappropriate given that \textit{more intelligent than} is non-linear, but there's a large industry involved in producing such measurements.) And this temptation leads to some prima facie plausible objections to my theory. (All of these objections arose in the discussion of the paper at BSPC.)

\subsubsection*{True and Truer (due to Cian Dorr)}

Here's an odd consequence of my theory plus the plausible assumption that \textit{If S then S is true} is axiomatic. We can't infer from \(A\) is true and \(B\) is false that \(A\) is truer than \(B\). But this looks like a reasonably plausible inference.

If we added this as inference rule, we would rule out all intermediate sentences. To prove this assume, for \textit{reductio}, that \(A\) is intermediate. Since we keep classical logic, we know \(A \vee \neg A\) is true. If\textit{ A}, then \(A\) is true, and hence \(\neg A\) is false. Then the new this inference rule implies \(A \geqslant _T \neg A\), hence \(A\)${\wedge}{\neg}$\(A \geqslant _T \neg A\), since \(\neg A \geqslant _T \neg A\), and hence 0=1\(\geqslant _T \neg A\), since 0=1 \(\geqslant _T A \wedge \neg A\), and \(\geqslant _T\) is transitive. So \(A\) is determinately true, not intermediate. A converse proof shows that if \(\neg A\), then \(A\) is determinately false, not intermediate. So by (\(\vee\){}-Out) it follows that \(A\) is not intermediate, but since \(A\) was arbitrary, there are no intermediate truths. So this rule is unacceptable, despite its plausibility.

\subsubsection*{Comparing Negative and Positive (due to Jonathan Schaffer)}

Let \(a\) be a regular borderline case of genius, somewhere near the middle of the penumbra. Let \textit{b} be someone who is not a determinate case of genius, but is very close. Let \(A\) be \textit{a is a genius} and \(B\) be \textit{b is a genius}. It seems plausible that \(A \geqslant _T \neg B\), since \(a\) is right around the middle of the borderline cases of genius, but \textit{b} is only a smidgen short of clear genius. But since \textit{b} is closer to being a genius than \(a\), we definitely have \(B \geqslant _T A\). By transitivity, it follows that \(B \geqslant _T \neg B\), hence \(B\) is determinately true (by the reasoning of the last paragraph). Since \(\neg B\) is not determinately false, it follows that \(B \wedge \neg B\)~is not determinately false, contradicting (A7).

Since I accept (A7) I must reject the initial assumption that \(A \geqslant _T \neg B\). But it's worth noting that this case is quite general. Similar reasoning could be used to show that for any indeterminate propositions of the form \(x\) \textit{is a genius} and \textit{y} \textit{is not a genius}, the first is not truer than the second. This seems odd, since intuitively these could both be indeterminate while the first is very nearly true and the second very nearly false.

\subsubsection*{Comparing Different Predicates (due to Elizabeth Harman)}

One intuitive way to understand the behaviour of \textit{truer} is that \(A\) is truer than \(B\) iff \(A\) is true on every admissible precisification on which \(B\) is true and the converse does not hold. This can't be an analysis of \textit{truer}, since it assumes we can independently define what is an admissible precisification, and this seems impossible. But it's a useful heuristic. And reflecting on it brings up a surprising consequence of my theory. If we assume that precisifications of predicates from different subject areas (e.g. \textit{hexagonal }and \textit{honest})\textit{ }are independent, it follows that subject-predicate sentences involving those predicates and indeterminate instances of them are incomparable with respect to truth. But this seems implausible. If France is a borderline case of being hexagonal that is close to the lower bound, and George Washington is a borderline case of being honest who is close to the upper bound, then we should think \textit{George Washington is honest} is truer than \textit{France is hexagonal}.

\bigskip

\noindent All three of these objections seem to me to turn on an underlying intuition that \textit{truer} should be a linear relation. If we are given this, then the inference principle Dorr suggests looks unimpeachable, and the comparisons Schaffer and Harman suggested look right. But once we drop the idea that truer is linear, I think the plausibility of these claims falls away. So the arguments against linearity are ipso facto arguments that we should simply drop the intuitions Dorr, Schaffer and Harman are relying upon.

To conclude, it's worth noting that a very similar inferential rule to the rule Dorr suggests is admissible. From the fact that \(A\) is determinately true, and \(B\) is determinately false, it follows that \(A\) is truer than\textit{ B}. If we assume, as seems reasonable, that we're only in a position to \textit{say} that \(A\) is true when it is determinately true, then whenever we're in a position to say \(A\) is true and \(B\) is false, it will be true that \(A\) is truer than \(B\). This line of defence is obviously similar to the explanation I gave in the previous section of why Sorites premises look plausible, and to the argument Rosanna Keefe gives that the failure of classical inference rules is no difficulty for supervaluationism because it admits very similar inference rules \citep{Keefe2000}. 

%
%{\itshape
%References}
%
%Braun, David and Theodore Sider (ms.) ``Vague, so Untrue''.
%
%Burgess, John (2001) ``Vagueness, Epistemicism and Response-Dependence'' \textit{Australasian Journal of Philosophy }79: 507\nobreakdash-24.
%
%Burgess, John and I. L. Humberstone, (1987) ``Natural Deduction Rules for a Logic of Vagueness'' \textit{Erkenntnis} 27:~197\nobreakdash-229.
%
%Cook, Roy (2002) ``Vagueness and Mathematical Precision'' \textit{Mind} 111: 225-48.
%
%Dummett, Michael (1959) ``Truth'' \textit{Proceedings of the Aristotelian Society. New Series }59: 141-62.
%
%Eklund, Matti (2002) ``Inconsistent Languages'' \textit{Philosophy and Phenomenological Research }64: 251-75.
%
%Fine, Kit (1975) ``Vagueness, Truth and Logic'' \textit{Synthese }30: 265-300.
%
%Goldblatt, Robert (1992) \textit{Logics of Time and Computation}. Palo Alto: CSLI.
%
%Graff, Delia (2000) ``Shifting Sands: An Interest-Relative Theory of Vagueness'' \textit{Philosophical Topics} 28:~45\nobreakdash-81.
%
%Greenough, Patrick (2003) ``Vagueness: A Minimal Account'' \textit{Mind} 112: 235\nobreakdash-81.
%
%Grice, H. Paul (1989) \textit{Studies in the Way of Words}. Cambridge, MA: Harvard University Press.
%
%Keefe, Rosanna (2000) \textit{Theories of Vagueness}. Cambridge: Cambridge University Press.
%
%Levinson, Stephen (2000) \textit{Presumptive Meanings}. Cambridge, MA: MIT Press.
%
%Lewis, David (1972) ``Psychophysical and theoretical identifications'' \textit{Australasian Journal of Philosophy }50:~249\nobreakdash-58
%
%McGee, Vann and Brian McLaughlin (1998) Review of Timothy Williamson's ``Vagueness'' \textit{Linguistics and Philosophy}, 21: 221-231.
%
%Sedivy, J., M. Tanenhaus, C. Chambers and G. Carlson (1999) ``Achieving incremental semantic interpretation through contextual representation'' \textit{Cognition}, 71: 109-47.
%
%Sider, Theodore (2001) ``Personal Identity and the Limits of Conceptual Analysis'' \textit{Philosophical Perspectives} 15:~189-209.
%
%Soames, Scott (1999) \textit{Understanding Truth}. New York: Oxford University Press. 
%
%Sorensen, Roy (2001) \textit{Vagueness and Contradiction}. Oxford: Oxford University Press.
%
%Tappenden, Jamie (1993) ``The Liar and Sorites Paradoxes; Toward a Unified Treatment'' \textit{Journal of Philosophy} 90:~551\nobreakdash-77.
%
%Weatherson, Brian (2003a) ``Epistemicism, Parasites and Vague Names'' \textit{Australasian Journal of Philosophy} 81:~276\nobreakdash-9.
%
%Weatherson, Brian (2003b) Critical Notice of Rosanna Keefe, ``Theories of Vagueness'', \textit{Philosophy and Phenomenological Research} xx: xx-xx.
%
%Williamson, Timothy (1994) \textit{Vagueness}. London: Routledge.
%
%Williamson, Timothy (1995) ``Definiteness and Knowability'' \textit{Southern Journal of Philosophy} 33 (Supp): 171\nobreakdash-91.
%
%Williamson, Timothy (2004) ``Reply to McGee and McLaughlin'' \textit{Linguistics and Philosophy} 27: 113-122.
%
